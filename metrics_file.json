{"genres_metrics": [{"genre": "Sertanejo", "metrics": {"fp": "658", "f-measure": "0.59005879209", "recall": "0.835098335855", "precision": "0.456198347107", "tp": "552", "tn": "1986", "fn": "109", "accuracy": "0.767927382753"}}, {"genre": "MPB", "metrics": {"fp": "146", "f-measure": "0.52602739726", "recall": "0.435703479576", "precision": "0.663594470046", "tp": "288", "tn": "2498", "fn": "373", "accuracy": "0.842965204236"}}, {"genre": "Ax\u00e9", "metrics": {"fp": "146", "f-measure": "0.665012406948", "recall": "0.608169440242", "precision": "0.733576642336", "tp": "402", "tn": "2498", "fn": "259", "accuracy": "0.877458396369"}}, {"genre": "Funk Carioca", "metrics": {"fp": "76", "f-measure": "0.830158730159", "recall": "0.791225416036", "precision": "0.873121869783", "tp": "523", "tn": "2568", "fn": "138", "accuracy": "0.935249621785"}}, {"genre": "Samba", "metrics": {"fp": "173", "f-measure": "0.580425531915", "recall": "0.515885022693", "precision": "0.663424124514", "tp": "341", "tn": "2471", "fn": "320", "accuracy": "0.850832072617"}}], "classifier_metrics": [{"macro": {"fp": "239.8", "f-measure": "0.638336571674", "recall": "0.63721633888", "precision": "0.677983090757", "tp": "421.2", "tn": "2404.2", "fn": "239.8", "accuracy": "0.854886535552"}}, {"micro": {"fp": "1199.0", "f-measure": "0.63721633888", "recall": "0.63721633888", "precision": "0.63721633888", "tp": "2106.0", "tn": "12021.0", "fn": "1199.0", "accuracy": "0.854886535552"}}], "test_details": {"clf": "NAIVE BAYES DEFAULT", "feature": "BINARY", "case-folding": "True", "stemming": "True", "remove_stopwords": "True", "test_number": "1"}}