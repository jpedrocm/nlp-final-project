[{"genres_metrics": [{"genre": "Sertanejo", "metrics": {"fp": "699", "f-measure": "0.59067357513", "recall": "0.862329803328", "precision": "0.449172576832", "tp": "570", "tn": "1528", "fn": "91", "accuracy": "0.726454293629"}}, {"genre": "MPB", "metrics": {"fp": "134", "f-measure": "0.545288197621", "recall": "0.450832072617", "precision": "0.689814814815", "tp": "298", "tn": "1800", "fn": "363", "accuracy": "0.808477842004"}}, {"genre": "Ax\u00e9", "metrics": {"fp": "133", "f-measure": "0.659915611814", "recall": "0.591527987897", "precision": "0.746183206107", "tp": "391", "tn": "1707", "fn": "270", "accuracy": "0.838864454218"}}, {"genre": "Funk Carioca", "metrics": {"fp": "73", "f-measure": "0.8256", "recall": "0.780635400908", "precision": "0.876061120543", "tp": "516", "tn": "1582", "fn": "145", "accuracy": "0.905872193437"}}, {"genre": "Samba", "metrics": {"fp": "168", "f-measure": "0.560763888889", "recall": "0.488653555219", "precision": "0.65784114053", "tp": "323", "tn": "1775", "fn": "338", "accuracy": "0.805683563748"}}], "classifier_metrics": [{"macro": {"fp": "241.4", "f-measure": "0.636448254691", "recall": "0.634795763994", "precision": "0.683814571765", "tp": "419.6", "tn": "1678.4", "fn": "241.4", "accuracy": "0.817070469407"}}, {"micro": {"fp": "1207.0", "f-measure": "0.634795763994", "recall": "0.634795763994", "precision": "0.634795763994", "tp": "2098.0", "tn": "8392.0", "fn": "1207.0", "accuracy": "0.812926224427"}}], "test_details": {"clf": "NAIVE BAYES DEFAULT", "feature": "BINARY", "case-folding": "True", "stemming": "True", "remove_stopwords": "True", "test_number": "1"}}]